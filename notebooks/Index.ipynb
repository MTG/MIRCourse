{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "Below, a sorted list of notebooks included in the MIR course repository is presented. At this point, the content is limited to the notebooks prepared by Baris Bozkurt (*except Lecture2_step4 by Vsevolod Eremenko and Lecture4_1 by Sankalp Gulati*) for the first part of the course focusing on basic feature extraction for MIR.\n",
    "\n",
    "In the notebooks folder, there exist two types of notebooks for some of the tasks (example: *ReviewLecture_1_HelloSpectrum.ipynb* and *ReviewLecture_1_HelloSpectrum_solution.ipynb*). *_solution.ipynb* includes the complete version and the other simply have some spaces for you to fill in as an exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review lectures\n",
    "\n",
    "The MIR course is offered in the second trimester of [Master in Sound and Music Computing](https://www.upf.edu/web/smc) at UPF/Barcelona and assumes the students have already taken the [Audio Signal Processing for Music Applications course](https://www.upf.edu/web/smc/audio-signal-processing-for-music-applications). As some of the brain cells and connections get deleted during the semester break, it is a good idea to consider a few review tasks and warm up for the new content. The following notebooks are prepared to help you warm up. \n",
    "\n",
    "**\"Hello world\" examples for sound processing:**\n",
    "* [ReviewLecture_1_HelloSpectrum](ReviewLecture_1_HelloSpectrum.ipynb): Read a sound file, plot the log amplitude spectrum of the signal. ([the completed notebook](ReviewLecture_1_HelloSpectrum_solution.ipynb))\n",
    "* [ReviewLecture_2_EnergyOfASignal](ReviewLecture_2_EnergyOfASignal.ipynb): Computing  low-level feature and plotting synchronously with waveform of the sound signal ([the completed notebook](ReviewLecture_2_EnergyOfASignal_solution.ipynb))\n",
    "* [ReviewLecture_3_HelloSpectrogram](ReviewLecture_3_HelloSpectrogram.ipynb): Read a sound file, plot amplitude spectrogram ([the completed notebook](ReviewLecture_3_HelloSpectrogram_solution.ipynb)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1:\n",
    "In the first lecture we aim to review basic flow in an MIR classification task and also start considering low-level feature extraction tasks.\n",
    "\n",
    "* [Lecture1_IntroWithACaseStudy](Lecture1_IntroWithACaseStudy.ipynb) discusses the task of automatic musical instrument classification on a limited sized dataset. The notebook includes implementation for: raw data analysis and preprocessing(segmentation), feature extraction using Essentia, analysis and preprocessing of features(normalisation), classifier design using an SVM model, testing of the classifier, finally comparative tests using various classifiers\n",
    "* [Lecture1_step1](Lecture1_step1.ipynb) considers low-level feature extraction, statistical feature extraction and further visualizing samples on statistical feature spaces ([the completed notebook](Lecture1_step1_solution.ipynb)). [Lecture1_step2_usingEssentiaStandard](Lecture1_step2_usingEssentiaStandard.ipynb) demonstrates use of Essentia-standard for feature extraction within the same settings.\n",
    "* [Lecture1_step3_cepstrum](Lecture1_step3_cepstrum.ipynb) demonstrates computation of the cepstrum and use of it for computing spectral envelope. Followed by [Lecture1_step4_essentiaExample_MFCC](Lecture1_step4_essentiaExample_MFCC.ipynb) which is an example of Essentia - MFFC function application on the same sound signal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2:\n",
    "\n",
    "In the second lecture we discuss the pitch space. Here are the notebooks:\n",
    "* [Lecture2_step1_F0AutoCorr](Lecture2_step1_F0AutoCorr.ipynb) is on implementing autocorralation based pitch detector ([the completed notebook](Lecture2_step1_F0AutoCorr_solution.ipynb)).\n",
    "* [Lecture2_step2_EssPreDomMel](Lecture2_step2_EssPreDomMel.ipynb) demonstrates the use of the predominant melody extraction function of Essentia, discusses the influence of analysis parameters on the estimated pitch info and also demonstrate use of [mir_eval](https://github.com/craffel/mir_eval) library to evaluate performance of a pitch extractor. \n",
    "* [Lecture2_step3_summingBandEnergies](Lecture2_step3_summingBandEnergies.ipynb) considers chromagram computation ([the completed notebook](Lecture2_step3_summingBandEnergies.ipynb)) \n",
    "* [Lecture2_step4_ChordDetectionDemo](Lecture2_step4_ChordDetectionDemo.ipynb) demonstrates automatic chord detection using chroma features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3:\n",
    "In Lecture 3, we discuss the rhythm aspect. \n",
    "* In [Lecture3_step1_noveltyFunctions](Lecture3_step1_noveltyFunctions.ipynb), some common novelty functions are implemented ([the completed notebook](Lecture3_step1_noveltyFunctions_solution.ipynb)) \n",
    "* [Lecture3_step2_Onset_Beat_Detection](Lecture3_step2_Onset_Beat_Detection.ipnb) demonstrates the use of Essentia onset detection functions (using HFC and complex spectral difference) and a beat-tracker.\n",
    "* [Lecture3_step3_Tempogram_autoCorr](Lecture3_step3_Tempogram_autoCorr.ipynb) includes a simple tempogram computation and demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4:\n",
    "Lecture 4 considers MIR for mon-Western music traditions:\n",
    "* [Lecture4_1_downloadAllSARAGAContent](Lecture4_1_downloadAllSARAGAContent.ipynb) includes sample code to download Hindustani and Carnatic music data from CompMusic servers\n",
    "* [Lecture4_2_visualizeAnnotations](Lecture4_2_visualizeAnnotations.ipynb) aims at demonstrating some of the contents of Saraga database annotations: sections, typical phrases, sama and tempo annotations.\n",
    "* [Lecture4_3_tuningAnalysis_SingleRecording](Lecture4_3_tuningAnalysis_SingleRecording.ipynb) considers tuning analysis of a recording of Turkish makam music and [Lecture4_4_tuningAnalysis_SetOfRecordings](Lecture4_4_tuningAnalysis_SetOfRecordings.ipynb) does the same job and merges the outputs to gather information required for building a makam scale model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 5:\n",
    "Introduction to MIR using symbolic data\n",
    "* [Lecture5_music21_intro](Lecture5_music21_intro.ipynb) is a very short introduction to music21, a toolkit for computational aided musicology\n",
    "* [Lecture5_melodicSegmentation](Lecture5_melodicSegmentation.ipynb) Melodic segmentation using Local Boundary Detection Model (LBDM by Cambouropoulos, E. (2001)).\n",
    "* [Lecture5_matchingTimeSeriesData](Lecture5_matchingTimeSeriesData.ipynb) discusses the problem of matching time-series data (such as finding short melody sequences within songs)\n",
    "\n",
    "... to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
